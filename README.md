# Improving photos with image-generating AI

## Idea

The beauty of a photo, a painting, or other works of art, is of course subjective.

[Here](https://www.researchgate.net/publication/351827395_A_Comprehensive_Survey_on_Computational_Aesthetic_Evaluation_of_Visual_Art_Images_Metrics_and_Challenges) is a survey on what has been done in the literature when attempting to evaluate the esthetics of photos and painting.

Even though the matter remains highly subjective, as said earlier, in photography there are some non-normative "rules" that are generally considered to produce images more pleasing to the human eye. One such rule is the [rule of thirds](https://en.wikipedia.org/wiki/Rule_of_thirds).

The nice thing about the rule of thirds is that it can be expressed mathematically. If we consider an image of size W x H, with a subject (e.g., a face) centred at position $(\bar{x},\bar{y})$, then we can define a *rule of thirds metric* $RT$ for example as the Kullback-Leibler distance between a distribution $P$ representing the subject, e.g. a Gaussian 
$$P(x,y)=\mathcal{N}(\bar{x},\bar{y},\sigma),$$
and a distribution representing the "thirds" grid, i.e.
$$Q(x,y)=\delta\left(x-\frac{W}{3}\right) + \delta\left(x-\frac{2W}{3}\right) + \delta\left(y-\frac{H}{3}\right) + \delta\left(y-\frac{2H}{3}\right),$$
where $\delta$ is the Dirac function.

The metric then would become
$$RT(\bar{x},\bar{y}) := D_{KL}(P, Q),$$
where a value of 0 would indicate a perfect match with the rule.

(There might be better ways to define it, this is just an example.)

(There are other similar "rules" that would provide a similar objective-wanna-be metric.)


Are images generated by AI esthetically pleasing?
If so, can we use AI's artistic power to improve (or suggest how to improve) pictures taken by humans?

## Tasks

Here is a list of possible tasks:
1. Review the literature on the esthetic sense of image-generating AI models. The paper cited above could be a start, but there might be better sources.
2. Check if the above-mentioned metric makes sense. Do pictures shot by professionals get a high score? Does it correlate with other ways of evaluating esthetics?
3. Regardless of the outcome of point 2, we can design a pipeline that, provided an input image, would
     - either change it to make it more pleasing,
     - or suggest in some way to the user how to improve it.

A possible pipeline for the last point is:
- Use a model to segment the input image and recognise the subject(s). Using a segmentation mask instead of the original input would also address possible privacy concerns in a real-world application.
- Part that improves the image. I can think of three possibilities:
    1. Using an image-to-text model to get a description of the image and then use an LLM to provide suggestions on how to improve it. This approach relies on the photography skills of the LLM, if it has any.
    2. Using an image-to-text model to get a description of the image and then feeding that description to a text-to-image model, and checking how good is the outcome. This approach relies on us having a way to measure how good is the outcome (that could be the rule of thirds metric if it works).
    3. Using an image-to-image auto-encoder to change the input image and make it better. Does the autoencoder need to be trained specifically to do this or pre-trained ones would work? If training is needed, that would be too demanding for this project.
